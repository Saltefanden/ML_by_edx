{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "## Linear classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datapoint():\n",
    "    def __init__(self, data: list, label: int):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "\n",
    "def dot(a: list, b: list) -> float:\n",
    "    if len(a) != len(b):\n",
    "        raise TypeError(f\"Dimension mismatch {len(a)=}, {len(b)=}\")\n",
    "    \n",
    "    return sum(x*y for x,y in zip(a,b))\n",
    "\n",
    "def test_perceptron(theta, datapoints):\n",
    "    return all([((dot(theta, datapoint.data)>0) * 2-1) == datapoint.label for datapoint in datapoints])\n",
    "\n",
    "\n",
    "def loud_perceptron(datapoints):\n",
    "    theta = [0,0]\n",
    "    th_list = []\n",
    "    mistakes = 0 \n",
    "    while (not test_perceptron(theta, datapoints)):\n",
    "        for datapoint in datapoints:\n",
    "            if dot(datapoint.data, theta)*datapoint.label<=0:\n",
    "                mistakes+=1\n",
    "                theta = [th + datapoint.label * datapoint.data[idx] for idx, th in enumerate(theta)]\n",
    "                th_list.append(theta)\n",
    "    print(f\"{mistakes = },\\n{th_list = }\")\n",
    "    return theta\n",
    "\n",
    "def loud_perceptron_with_offset(datapoints, max_mistakes = 100):\n",
    "    theta = [0,0]\n",
    "    theta0 = 0\n",
    "    th_list = []\n",
    "    mistakes = 0 \n",
    "    while (not test_perceptron(theta, datapoints)):\n",
    "        for datapoint in datapoints:\n",
    "            if dot(datapoint.data, theta)*datapoint.label<=0:\n",
    "                mistakes+=1\n",
    "                if mistakes >=max_mistakes:\n",
    "                    print(f\"Ran through too many mistakes: {mistakes=}\")\n",
    "                    return None\n",
    "                theta = [th + datapoint.label * datapoint.data[idx] for idx, th in enumerate(theta)]\n",
    "                th_list.append(theta)\n",
    "                theta0 += datapoint.label\n",
    "    print(f\"{mistakes = },\\n{th_list = }\")\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Perceptron mistakes\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&d1: \\quad x^{(1)} = [-1, -1], \\quad y^{(1)} = 1\\\\\n",
    "&d2: \\quad x^{(2)} = [1, 0], \\quad\\quad y^{(2)} = -1\\\\\n",
    "&d3: \\quad x^{(3)} = [-1, 1.5], \\quad y^{(3)} = 1\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Datapoint([-1, -1], 1)\n",
    "d2 = Datapoint([1, 0], -1)\n",
    "d3 = Datapoint([-1, 1.5], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A:\n",
    "How many mistakes does the algorithm make until convergence if the algorithm starts with data point $x^{(1)}$? How many mistakes does the algorithm make if it starts with data point $x^{(2)}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1, x2, x3:\n",
      "mistakes = 2,\n",
      "th_list = [[-1, -1], [-2, 0.5]]\n",
      "\n",
      "x2, x3, x1:\n",
      "mistakes = 1,\n",
      "th_list = [[-1, 0]]\n"
     ]
    }
   ],
   "source": [
    "print('x1, x2, x3:')\n",
    "\n",
    "loud_perceptron([d1, d2, d3])\n",
    "\n",
    "print('\\nx2, x3, x1:')\n",
    "\n",
    "loud_perceptron([d2, d3, d1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B:\n",
    "\n",
    "In part (a), what are the factors that affect the number of mistakes made by the algorithm?\n",
    "\n",
    "***Answer: Iteration order***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C:\n",
    "Now assume that $x^{(3)} = [-1, 10]$. How many mistakes does the algorithm make until convergence if cycling starts with data point $x^{(1)}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistakes = 6,\n",
      "th_list = [[-1, -1], [-2, 9], [-3, 8], [-4, 7], [-5, 6], [-6, 5]]\n"
     ]
    }
   ],
   "source": [
    "d3_c = Datapoint([-1, 10], 1)\n",
    "loud_perceptron([d1, d2, d3_c]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please enter the number of mistakes of Perceptron algorithm if the algorithm starts with $x^{(2)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mistakes = 1,\n",
      "th_list = [[-1, 0]]\n"
     ]
    }
   ],
   "source": [
    "loud_perceptron([d2, d3_c, d1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D: \n",
    "For a fixed iteration order, what are the factors that affect the number of mistakes made by the algorithm between part (a) and part (c)?\n",
    "\n",
    "***Answer: Maximum norm between data points***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E: (Optional)\n",
    "In 1962, Novikoff has proven the following theorem.\n",
    "\n",
    "Assume:\n",
    "\n",
    "- There exists $\\theta^{\\ast}$ such that $\\dfrac{y^{(i)}\\left(\\theta^\\ast \\cdot x^{(i)} \\right)}{|\\theta^{\\ast}|}\\ge \\gamma$ for all $i = 1, \\ldots, n$ and some $\\gamma>0$ \n",
    "\n",
    "- All the examples are bounded $|x^{(i)}|\\le R, \\quad i = 1, \\ldots, n.$\n",
    "\n",
    "Then the number $k$ of updates made by the perceptron algorithm is bounded by $\\frac{R^2}{\\gamma^2}$.\n",
    "\n",
    "(Note that the first condition implies that the data is linearly separable)\n",
    "\n",
    "For proof, refer to theorem 1 [of this paper](https://arxiv.org/pdf/1305.0208.pdf). Based on this theorem, what are the factors that constitute the bound on the number of mistakes made by the algorithm?\n",
    "\n",
    "***Answer: Max margin between positive and negative datapoints and max norm of datapoints***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Perceptron performance:\n",
    "\n",
    "### A:\n",
    "\n",
    "The following table shows a data set and the number of times each point is misclassified during a run of the perceptron algorithm (with offset $\\theta_0$). $\\theta$ and $\\theta_0$ are initialized to zero.\n",
    "\n",
    "$$\n",
    "\\begin{array}{l l l c}\n",
    "            i   &   x^{(i)}     &   y^{(i)}     &   \\text{times misclassified}\\\\ \n",
    "\\hline          &               &               &       \\\\\n",
    "            1   &   [-4,2]      &   +1          &   1   \\\\\n",
    "            2   &   [-2,1]      &   +1          &   0   \\\\\n",
    "            3   &   [-1,-1]     &   -1          &   2   \\\\\n",
    "            4   &   [2,2]       &   -1          &   1   \\\\\n",
    "            5   &   [1,-2]      &   -1          &   0   \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "write down the state of $\\theta$ and $\\theta_0$ after this run has completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th_list = [[-4, 2], [-3, 3], [-5, 1], [-4, 2]]\n",
      "theta0=-2\n"
     ]
    }
   ],
   "source": [
    "theta = [0,0]\n",
    "theta0 = 0\n",
    "th_list = []\n",
    "\n",
    "d1 = Datapoint([-4,2],1)\n",
    "d3 = Datapoint([-1, -1],-1)\n",
    "d4 = Datapoint([2,2],-1)\n",
    "\n",
    "datapoints = [d1, d3, d4, d3]\n",
    "\n",
    "for datapoint in datapoints:\n",
    "    theta = [th + datapoint.label * datapoint.data[idx] for idx, th in enumerate(theta)]\n",
    "    th_list.append(theta)\n",
    "    theta0 += datapoint.label\n",
    "\n",
    "print(f\"{th_list = }\\n{theta0=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B:\n",
    "Provide one example of a different initialization of $\\theta$ such that the perceptron algorithm with this initialization would not produce any mistakes during a run through the data.\n",
    "\n",
    "***Answer:***   \n",
    "$\\theta = [-1,1]$ and $\\theta_0 = -0.5$ such that the line equation is $x_2 = x_1 + 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C:\n",
    "\n",
    "The theorem from question 1. (e) provides an upper bound on the number of steps of the Perceptron algorithm and implies that it indeed converges. In this question, we will show that the result still holds even when $\\theta$ is not initialized to 0\n",
    "\n",
    "In other words: Given a set of training examples that are linearly separable through the origin, show that the initialization of $\\theta$ does not impact the perceptron algorithm's ability to eventually converge.\n",
    "\n",
    "To derive the bounds for convergence, we assume the following inequalities holds:\n",
    "\n",
    "- There exists $\\theta^{\\ast}$ such that $\\dfrac{y^{(i)}\\left(\\theta^\\ast \\cdot x^{(i)} \\right)}{|\\theta^{\\ast}|}\\ge \\gamma$ for all $i = 1, \\ldots, n$ and some $\\gamma>0$ \n",
    "\n",
    "- All the examples are bounded $|x^{(i)}|\\le R, \\quad i = 1, \\ldots, n.$\n",
    "\n",
    "If $\\theta$ is initialized to 0, we can show by induction that:\n",
    "\n",
    "$$\\theta^{(k)} \\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|}\\ge k\\gamma$$\n",
    "\n",
    "For instance,\n",
    "\n",
    "$$\\theta^{(k+1)} \\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|} = \\left(\\theta^{(k)} + y^{(i)}x^{(i)}\\right) \\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|} \\ge (k+1)\\gamma$$\n",
    " \n",
    "If we initialize $\\theta$ to a general (not necessarily 0) $\\theta^{(0)}$, then:\n",
    "\n",
    "$$\\theta^{(k)} \\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|}\\ge a+k\\gamma$$\n",
    " \n",
    "Determine the formulation of $a$ in terms of $\\theta^\\ast$ and $\\theta^{(0)}$:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***Answer:***\n",
    "\n",
    "First notice that due to the update rules:\n",
    "$$\\theta^{(k)} = \\theta^{(0)} + y^{(i_1)}x^{(i_1)} + \\ldots + y^{(i_k)}x^{(i_k)}$$\n",
    "\n",
    "where we have defined $y^{(i_n)}x^{(i_n)}$ as the $n'th$ pair of mistake points.\n",
    "\n",
    "This gives us the following expression:\n",
    "$$\\theta^{(k)} \\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|} = \\theta^{(0)}\\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|} + y^{(i_1)}x^{(i_1)}\\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|} + \\ldots + y^{(i_k)}x^{(i_k)}\\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|}$$\n",
    "\n",
    "Due to the definition of $\\theta^\\ast$: $\\dfrac{y^{(i)}\\left(\\theta^\\ast \\cdot x^{(i)} \\right)}{|\\theta^{\\ast}|}\\ge \\gamma$ for all $i = 1, \\ldots, n$ we can put a bound on $\\theta^{(k)} \\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|}$:\n",
    "\n",
    "$$\\theta^{(k)} \\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|} \\ge \\theta^{(0)}\\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|} + \\underbrace{\\gamma + \\ldots + \\gamma}_\\text{k times} = \\theta^{(0)}\\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|} + k\\gamma$$\n",
    "\n",
    "thus:\n",
    "\n",
    "$$a = \\theta^{(0)}\\cdot \\dfrac{\\theta^\\ast}{|\\theta^\\ast|} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Decision Boundaries\n",
    "\n",
    "General knowledge, not too important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Linear Support Vector Machines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
